# Caching

- Cache is faster storage subset copy access, usually at expense of money, and storage limitation
- Lower latency, higher throughput in caching
- Decrease network cost
- Example: Avoid making a http GET request for static javascript content, instead save it on our computer (disk cache)
- HTTP header cache-control can be used. Ex: max-age=3600
- HTTP head: x-cache: HIT/MISS -> cache exists/expired
- HTTP cache is stored on disk, which is still much faster than network
- Cache Ratio: Cache hits/(hits+miss). We want this higher
- Try to use caching wherever possible, to speed up
- We could add caching to backend solution, by using the inmemory store using Redis
- Clever algorithms to selectively store elements in cache are used
- Write-around cache: skip cache and write to storage. Read attempt: miss, fetch from disk, copy to cache. Put only things on cache which are being read.
- Write-through cache: immediately write to cache, and disk
- Write back cache: write to cache, skip disk. Periodic dump to disk. Could risk data loss on server crashes.
- Depends on application which strategy to use
- Eviction Policy: Cache is limited in size, so need to evict existing data from cache. 
- FIFO eviction: Not always best, as first in may still be much used one
- LRU eviction: Least recently used
- LFU eviction: Least frequently used. Key->value of data object->used count